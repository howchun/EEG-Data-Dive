{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e946-QpFqm-M",
        "outputId": "410509f7-7b71-4b50-e0fb-2cc58ef29115"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Adam in /usr/local/lib/python3.10/dist-packages (0.0.0.dev0)\n"
          ]
        }
      ],
      "source": [
        "%pip install Adam\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import shutil\n",
        "\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential, model_from_json\n",
        "from keras.layers import Conv2D, MaxPooling2D, MaxPool2D, Dropout, Activation, Flatten, Dense\n",
        "\n",
        "from  tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "from keras import backend as k\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"eeg_data_S2_match.csv\")"
      ],
      "metadata": {
        "id": "iGOli1NjM5_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.drop(['Trial', 'Alcoholic', 'Sensor', 'Sample','Matching_Condition', 'Subject_ID'], axis=1)  # Assuming 'Subject_ID' and 'Alcoholic' are not features\n",
        "y = data['Alcoholic']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "clf = RandomForestClassifier()\n",
        "\n",
        "# Train the classifier\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "zk5A9V26rnGg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f28df30-22c3-417c-aed7-625d4099d129"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7160493827160493\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "model = tf.keras.models.Sequential([\n",
        "    # First Convolution\n",
        "    tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=input_shape),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    # Second Convolution\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    # Third Convolution\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    # Flatten\n",
        "    tf.keras.layers.Flatten(),\n",
        "    # Dense layer\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')  # softmax\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy', #categorical_cross_entropy\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "h4VKMvThqq_7",
        "outputId": "ec3f0c63-6268-42b9-fb8a-e4cdce2e9b44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'input_shape' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-3428404f0db8>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m model = tf.keras.models.Sequential([\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# First Convolution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Second Convolution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'input_shape' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"eeg_data_S2_nomatch.csv\")"
      ],
      "metadata": {
        "id": "jx7Hqv21q4kq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.drop(['Trial', 'Alcoholic', 'Sensor', 'Sample','Matching_Condition', 'Subject_ID'], axis=1)  # Assuming 'Subject_ID' and 'Alcoholic' are not features\n",
        "y = data['Alcoholic']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "model = GradientBoostingClassifier(n_estimators=100,max_depth=5)\n",
        "\n",
        "# fit the model with the training data\n",
        "model.fit(X_train,y_train)\n",
        "\n",
        "# predict the target on the train dataset\n",
        "predict_train = model.predict(X_train)\n",
        "print('\\nTarget on train data',predict_train)\n",
        "\n",
        "# Accuray Score on train dataset\n",
        "accuracy_train = accuracy_score(y_train,predict_train)\n",
        "print('\\naccuracy_score on train dataset : ', accuracy_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhvpxZWv4z_y",
        "outputId": "3ac93b5f-f0e6-416a-fd72-2df089f2438f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Target on train data [False  True  True ... False False False]\n",
            "\n",
            "accuracy_score on train dataset :  0.6409841928331307\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.drop(['Trial', 'Alcoholic', 'Sensor', 'Sample','Matching_Condition', 'Subject_ID'], axis=1)  # Assuming 'Subject_ID' and 'Alcoholic' are not features\n",
        "y = data['Alcoholic']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "k_folds = KFold(n_splits = 5)\n",
        "\n",
        "scores = cross_val_score(clf, X, y, cv = k_folds)\n",
        "\n",
        "print(\"Cross Validation Scores: \", scores)\n",
        "print(\"Average CV Score: \", scores.mean())\n",
        "print(\"Number of CV Scores used in Average: \", len(scores))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHZCNlOs8mVX",
        "outputId": "6894da6f-8f16-4054-ecd1-5ba3e853d33d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross Validation Scores:  [0.15226306 0.19109653 0.54528982 0.48536116 0.36896315]\n",
            "Average CV Score:  0.3485947432266473\n",
            "Number of CV Scores used in Average:  5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "X = data.drop(['Trial', 'Alcoholic', 'Sensor', 'Sample','Matching_Condition', 'Subject_ID'], axis=1)  # Assuming 'Subject_ID' and 'Alcoholic' are not features\n",
        "y = data['Alcoholic']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "model = GaussianNB()\n",
        "\n",
        "# Model training\n",
        "model.fit(X_train, y_train)\n",
        "predict_train = model.predict(X_train)\n",
        "print('\\nTarget on train data',predict_train)\n",
        "\n",
        "# Accuray Score on train dataset\n",
        "accuracy_train = accuracy_score(y_train,predict_train)\n",
        "print('\\naccuracy_score on train dataset : ', accuracy_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IBHuJk7Cl89",
        "outputId": "ef1c7499-3674-4cf6-c013-d74b3fb06abd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Target on train data [ True  True  True ... False False  True]\n",
            "\n",
            "accuracy_score on train dataset :  0.6714223291880232\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_last_two_and_convert_to_int(value):\n",
        "    # Extract last 2 characters\n",
        "    last_two = value[-2:]\n",
        "    # Convert to int\n",
        "    return int(last_two)\n",
        "\n",
        "# Apply the function to the column\n",
        "# df['Column1'] = df['Column1'].apply(extract_last_two_and_convert_to_int)"
      ],
      "metadata": {
        "id": "XUYlVvXlHMP_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# LSTM for international airline passengers problem with regression framing\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pandas import read_csv\n",
        "import math\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "# convert an array of values into a dataset matrix\n",
        "def create_dataset(dataset, look_back=1):\n",
        " dataX, dataY = [], []\n",
        " for i in range(len(dataset)-look_back-1):\n",
        "  a = dataset[i:(i+look_back), 0]\n",
        "  dataX.append(a)\n",
        "  dataY.append(dataset[i + look_back, 0])\n",
        " return np.array(dataX), np.array(dataY)\n",
        "# fix random seed for reproducibility\n",
        "tf.random.set_seed(7)\n",
        "# load the dataset\n",
        "dataframe = read_csv('eeg_data_S2_match.csv')\n",
        "dataframe['Subject_ID'] = dataframe['Subject_ID'].apply(extract_last_two_and_convert_to_int)\n",
        "# dataframe['Matching_Condition'] = dataframe['Matching_Condition'].astype(int)\n",
        "x = dataframe.drop(['Sensor','Alcoholic', 'Sample', 'Matching_Condition', 'Trial'], axis=1)\n",
        "print(x)\n",
        "dataset = x.values\n",
        "print(dataset)\n",
        "dataset = dataset.astype('float32')\n",
        "# normalize the dataset\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "dataset = scaler.fit_transform(dataset)\n",
        "# split into train and test sets\n",
        "train_size = int(len(dataset) * 0.67)\n",
        "test_size = len(dataset) - train_size\n",
        "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
        "# reshape into X=t and Y=t+1\n",
        "look_back = 1\n",
        "trainX, trainY = create_dataset(train, look_back)\n",
        "testX, testY = create_dataset(test, look_back)\n",
        "# reshape input to be [samples, time steps, features]\n",
        "trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
        "testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
        "# create and fit the LSTM network\n",
        "model = Sequential()\n",
        "model.add(LSTM(4, input_shape=(1, look_back)))\n",
        "model.add(Dense(1))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "model.fit(trainX, trainY, epochs=2, batch_size=1, verbose=2)\n",
        "# make predictions\n",
        "trainPredict = model.predict(trainX)\n",
        "testPredict = model.predict(testX)\n",
        "trainPredict = trainPredict.reshape(-1, 1)\n",
        "\n",
        "# invert predictions\n",
        "trainPredict = scaler.inverse_transform(trainPredict)\n",
        "trainY = scaler.inverse_transform(trainY.reshape(-1, 1))  # Reshape trainY to match trainPredict\n",
        "testPredict = scaler.inverse_transform(testPredict)\n",
        "testY = scaler.inverse_transform(testY.reshape(-1, 1))\n",
        "# calculate root mean squared error\n",
        "trainScore = np.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
        "print('Train Score: %.2f RMSE' % (trainScore))\n",
        "testScore = np.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\n",
        "print('Test Score: %.2f RMSE' % (testScore))\n",
        "# shift train predictions for plotting\n",
        "trainPredictPlot = np.empty_like(dataset)\n",
        "trainPredictPlot[:, :] = np.nan\n",
        "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
        "# shift test predictions for plotting\n",
        "testPredictPlot = np.empty_like(dataset)\n",
        "testPredictPlot[:, :] = np.nan\n",
        "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n",
        "# plot baseline and predictions\n",
        "plt.plot(scaler.inverse_transform(dataset))\n",
        "plt.plot(trainPredictPlot)\n",
        "plt.plot(testPredictPlot)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "D-JrS9wfdj41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 894
        },
        "outputId": "b405695b-5397-4bef-dcb0-8146d4a421fc"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         Value  Subject_ID\n",
            "0        3.296          36\n",
            "1        3.296          36\n",
            "2        3.784          36\n",
            "3        4.761          36\n",
            "4        4.761          36\n",
            "...        ...         ...\n",
            "180219  -9.440          39\n",
            "180220  -7.975          39\n",
            "180221  -6.999          39\n",
            "180222  -7.487          39\n",
            "180223 -10.417          39\n",
            "\n",
            "[180224 rows x 2 columns]\n",
            "[[  3.296  36.   ]\n",
            " [  3.296  36.   ]\n",
            " [  3.784  36.   ]\n",
            " ...\n",
            " [ -6.999  39.   ]\n",
            " [ -7.487  39.   ]\n",
            " [-10.417  39.   ]]\n",
            "Epoch 1/4\n",
            "120748/120748 - 218s - loss: 1.1072e-04 - 218s/epoch - 2ms/step\n",
            "Epoch 2/4\n",
            "120748/120748 - 209s - loss: 3.8699e-05 - 209s/epoch - 2ms/step\n",
            "Epoch 3/4\n",
            "120748/120748 - 210s - loss: 3.8419e-05 - 210s/epoch - 2ms/step\n",
            "Epoch 4/4\n",
            "120748/120748 - 209s - loss: 3.7963e-05 - 209s/epoch - 2ms/step\n",
            "3774/3774 [==============================] - 7s 2ms/step\n",
            "1859/1859 [==============================] - 3s 2ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "non-broadcastable output operand with shape (120748,1) doesn't match the broadcast shape (120748,2)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-ddb76816072e>\u001b[0m in \u001b[0;36m<cell line: 57>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;31m# invert predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m \u001b[0mtrainPredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainPredict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0mtrainY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Reshape trainY to match trainPredict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0mtestPredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestPredict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36minverse_transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    539\u001b[0m         )\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: non-broadcastable output operand with shape (120748,1) doesn't match the broadcast shape (120748,2)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tyzaCzxul7Ng"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}